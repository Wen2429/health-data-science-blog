[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Multilevel Modelling,MLM",
    "section": "",
    "text": "MLM also has some synonyms or derivative models in different fields:\n\nHierarchical Linear Model,HLM\nLinear Mixed Model\nMixed Effects Model\nRandom Effects Model\nRandom Coefficients Model\nVariance Components Model\nGrowth Curve Model\n\nRegression analysis is the basis of almost all statistical models, and the most general form of regression analysis can be classified as the multilevel linear model HLM.\n\nThe t-test is a special case of ANOVA (the independent variable has only two levels)\nANOVA is a special case of regression analysis (independent variables are categorical variables)\nThe essence of regression analysis is the general linear model GLM (generalized linear model by extension)\nGLM is a special case of HLM (Level 1 only)\nMeta-analysis can be viewed as HLM with only group models (Level 2 only)\n\nDistinguish “multilevel linear models” from “hierarchical/stepwise multiple regression” :\n\nMultilevel linear model solves multi-layer nested structure data (the end point is the data structure)\nHierarchical/stepwise multiple regression itself is an ordinary regression analysis, which solves the priority of the importance of different independent variables (the goal is the importance of variables)."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "fixed effect vs. random effect",
    "section": "",
    "text": "FE and RE are too general for HLM, and HLM has a more detailed division:\n\n\n\nfixed intercept: The fixed intercept does not actually exist in the HLM model, but rather “relegates” to a general least squares regression (OLS), which is the most commonly used GLM regression analysis.\n\nm1 &lt;- lm(Y ~ 1 + X1 + X2, ...)\n\nrandom intercept: When doing HLM, it is common to set the intercept to be random, that is, to allow different groups to have their own intercept (baseline level). Some people are born at the end, while you are born at the beginning. In R, as long as you put parentheses after a regression expression ( instead of using ‘lm’, use the ‘lmer’ function from the ‘lme4’ and ‘lmerTest’ packages), The parentheses define the random part of the Level 1 intercept or slope at Level 2. (The random part of Level 1 is the individual residual, which we don’t have to define.) After the vertical bar “|” is the clustering/grouping variable (which can be a province or school, or an individual in a repeated measures or tracking design), the 1 in front of the vertical bar is the random intercept, and the variable name is the random slope associated with that variable.\n\nm2 &lt;- lmer(Y ~ 1 + X1 + X2 + (1 | group), ...)\n\nfixed slope: A fixed slope means that the slope of a Level 1 variable is consistent across groups. Although this may not be true, the researcher can assume and test whether the slopes are consistent across groups and not significantly different. Note that there is no distinction between fixed and random (or both) Level 2 intercepts or slopes, unless there is also Level 3.\n\nm3 &lt;- lmer(Y ~ 1 + X1 + X2 + (1 | group), ...)\n\nrandom slope: As opposed to a fixed slope, a random slope means that the slope of a Level 1 variable varies across groups, or “by group.” Some people spend two hours to make 10,000 yuan, but you only make 10 yuan. You can either include the random slope component without explaining the difference in slope, or you can include a Level 2 variable that interacts with the Level 1 variable (i.e., a cross-layer interaction) to explain why the effect of X varies by group and what causes the change.\n\nm4 &lt;- lmer(Y ~ 1 + X1 + X2 + (1 + X1 | group), ...) # We can omit the 1's, as they are included in the intercept by default (except for random intercepts)\nm5 &lt;- lmer(Y ~ 1 + X1*W + X2 + (1 + X1 | group), ...) # W is a Level 2 explanatory variable, and X1*W is a cross-layer interaction\n\nIn general, random intercepts are considered whenever HLM is used. So, when discussing FE or RE in the framework of HLM, it is more about whether the “slope” is fixed or random.\nSo when to use a fixed slope versus a random slope? There are four main considerations:\n\nTheoretical assumptions: We generally don’t assume a random slope, which means that setting a random slope requires a strong theoretical assumption that the effect of the Level 1 variable varies by group. This can also be tested statistically, and if the random part of the slope (the variance component) is not significantly different from zero, you might consider discarging the random slope.\nPurpose: If the purpose of our study is to test for cross-layer interactions, then the corresponding Level 1 independent variables need to be set to random slopes. This makes sense because the cross-layer interaction itself implies that the slope of X will change, and we want to explain why it will change, if you don’t set a random slope, wouldn’t you contradict yourself?\nNumber of groups at Level 2: If the number of groups at Level 2 is too small (e.g., &lt;10 groups), then the freedom at Level 2 is too small to make robust parameter estimates, so a fixed slope is more appropriate. – BUT! If the number of groups at Level 2 is really less than 10, we might even want to think twice about using HLM! Because the Level 2 group is also a kind of random sampling, we generally require the sample size to be at least 10 times the number of variables in GLM, and we also require the group size to be not too small in HLM, and generally require the Level 2 group to be at least 10-20 groups. Otherwise, the statistical test power of the Level 2 model will be seriously insufficient! This is the same as GLM! So, if we don’t have more than 10 samples, it’s probably best not to use the HLM, in which case we use what’s called a “fixed intercept” model, which downscales to GLM/ANOVA/ANCOVA!\nLevel 2 Sample Size within each group: Reminiscent of the classic between-subjects design ANOVA, we generally require a sample size of at least 30-50 participants per group to ensure power. The same point applies to HLM. If the sample size within each group at Level 2 is too small (e.g., &lt;30), you can still use HLM, but you’ll need more or all of the data to get robust parameter estimates, so a random slope is more appropriate."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Wen Chi’s blog",
    "section": "",
    "text": "fixed effect vs. random effect\n\n\n\n\n\n\nnotes\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nJun 16, 2025\n\n\nWen Chi\n\n\n\n\n\n\n\n\n\n\n\n\nMultilevel Modelling,MLM\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\nJun 16, 2025\n\n\nWen Chi\n\n\n\n\n\n\nNo matching items"
  }
]